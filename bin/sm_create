#!/usr/bin/env python

# stdlib imports
import sys
import os.path
import shutil
import argparse
import datetime
import json
import warnings

# third party imports
from libcomcat.search import get_event_by_id
from configobj import ConfigObj
from impactutils.time.ancient_time import HistoricTime

# local imports
from shakemap.utils.config import get_config_paths
from shakelib.rupture.origin import write_event_file, Origin
from shakelib.rupture.factory import text_to_json, rupture_from_dict_and_origin
from shakemap.utils.utils import get_network_name, migrate_gmpe, set_gmpe

TIMEFMT1 = '%Y-%m-%dT%H:%M:%S.%fZ'
TIMEFMT2 = '%Y-%m-%dT%H:%M:%S'
KM2SEC = 3600.0/111  # seconds per kilometer


def get_parser():
    description = '''
    "Clone" a ShakeMap from NEIC Comcat, or create an event from scratch.

    Notes on usage:

    eventid is a ComCat event ID.  For example, for this event:
    https://earthquake.usgs.gov/earthquakes/eventpage/us2000ar20
    The event ID is us2000ar20.

    If no source is specified, then the event ID used for the event directory,
    eventid field in event.xml file, and names of data and fault files will
    be that of the *authoritative* origin.

    If a source (us, ci, nc, etc.) is specified, then that ID is used instead
    of the authoritative ID.


    '''
    formatter = argparse.RawDescriptionHelpFormatter
    parser = argparse.ArgumentParser(
        description=description,
        formatter_class=formatter)
    parser.add_argument(
        'eventid',
        help='ID of the event to process')
    parser.add_argument(
        '-f', '--force', action='store_true',
        help='Force overwrite of event data.')
    parser.add_argument(
        '-s', '--source',
        help='Specify the source network of desired shakemap.')
    parser.add_argument(
        '-e', '--event',
        nargs=7,
        metavar=('NETID', 'TIME', 'LON', 'LAT',
                 'DEP', 'MAG', 'LOCSTR'),
        help='Specify the event parameters (locstr should '
             'be in quotes)')
    parser.add_argument(
        '-b', '--skip-bounds', action='store_true',
        default=False,
        help='Skip bounds set in online shakemap.')
    parser.add_argument(
        '-n', '--no-scenario', action='store_true',
        default=False,
        help='When used with -e, disable scenario mode.')
    parser.add_argument(
        '-p', '--preserve-params', action='store_true',
        default=False,
        help='Preserve model parameters detected in ComCat.')
    return parser


def _get_event_dictionary(detail, source):
    edict = None

    if source is not None:
        # get basic event information from an origin contributed by input
        # source
        try:
            origin = detail.getProducts('origin', source=source)[0]
            eventid = source + origin['eventsourcecode']
            edict = {
                'id': eventid,
                'netid': source,
                'network': get_network_name(source),
                'lat': float(origin['latitude']),
                'lon': float(origin['longitude']),
                'depth': float(origin['depth']),
                'mag': float(origin['magnitude']),
                'time': datetime.datetime.strptime(
                    origin['eventtime'], TIMEFMT1),
                'locstring': detail.location
            }
        except ValueError:
            print('No origin for event %s.' % source)
    else:  # no source specified, use detail object
        edict = {
            'id': detail.id,
            'netid': detail['net'],
            'network': get_network_name(detail['net']),
            'lat': detail.latitude,
            'lon': detail.longitude,
            'depth': detail.depth,
            'mag': detail.magnitude,
            'time': detail.time,
            'locstring': detail.location
        }
    return edict


def main(args):
    install_path, data_path = get_config_paths()
    if not os.path.isdir(data_path):
        print('%s is not a valid directory.' % data_path)
        sys.exit(1)

    # get the global config for modules.conf
    module_file = os.path.join(install_path, 'config', 'modules.conf')
    module_conf = ConfigObj(module_file)

    # get the global config for migrate.conf
    migrate_file = os.path.join(install_path, 'config', 'migrate.conf')
    migrate_conf = ConfigObj(migrate_file)

    if args.event:
        locstring = ''
        netid = args.event[0]
        timestr = args.event[1]
        time = HistoricTime.strptime(timestr, TIMEFMT2)
        lon = float(args.event[2])
        lat = float(args.event[3])
        depth = float(args.event[4])
        mag = float(args.event[5])
        locstring = args.event[6]

        # quick check of coordinates
        if lat > 90 or lat < -90:
            print('You seem to have flipped your lon/lat values. Exiting.')
            sys.exit(1)

        network = get_network_name(netid)
        if network == 'unknown':
            network = ''

        eventid = args.eventid
        if not args.no_scenario:
            if not args.eventid.endswith('_se'):
                eventid = eventid + '_se'

        edict = {
            'id': eventid,
            'netid': netid,
            'network': network,
            'time': time,
            'lat': lat,
            'lon': lon,
            'depth': depth,
            'mag': mag,
            'locstring': locstring
        }
        detail = None
    else:
        # Get the DetailEvent product for this event ID
        # regardless of input, the output directory and files
        # will contain the *authoritative* event ID from ComCat,
        # unless source is specified.
        try:
            detail = get_event_by_id(args.eventid)
        except Exception as e:
            print('Unable to connect to ComCat server.  Please try again later. "%s"')
            sys.exit(1)
        # get input data
        edict = _get_event_dictionary(detail, args.source)
        if edict is None:
            print('No event dictionary, quitting.')
            exit(1)
        eventid = edict['id']

    # check to see if the event directory exists
    event_dir = os.path.join(data_path, eventid, 'current')
    if not os.path.isdir(event_dir):
        os.makedirs(event_dir)
    else:
        if not args.force:
            print('Event directory %s already exists.  Use -f '
                  'option to overwrite.' % event_dir)
            sys.exit(1)
        shutil.rmtree(event_dir)
        os.makedirs(event_dir)

    # name the event.xml file
    event_xml_file = os.path.join(event_dir, 'event.xml')

    # write the event.xml file
    write_event_file(edict, event_xml_file)

    if detail is not None:
        # if this event has a shakemap, then we have more to do
        if not detail.hasProduct('shakemap'):
            print('Event %s has no ShakeMap product. '
                  'Creating a basic ShakeMap.'
                  % detail.id)
        else:
            if args.source:
                source = args.source
            else:
                source = 'preferred'
            try:
                shakemap = detail.getProducts('shakemap', source=source)[0]
            except AttributeError:
                msg = 'No ShakeMap product from source %s exists.' % source
                print(msg)
                sys.exit(0)

            data_file = os.path.join(event_dir, '%s_dat.xml' % eventid)
            shakemap.getContent('stationlist.xml', filename=data_file)
            fault_files = shakemap.getContentsMatching('fault.txt')
            if len(fault_files):
                fault_file = os.path.join(event_dir, fault_files[0])
                shakemap.getContent(fault_files[0], filename=fault_file)
                xmlfile = os.path.join(event_dir, 'event.xml')
                try:
                    jdict = text_to_json(fault_file, new_format=False)
                    origin = Origin(edict)
                    rupt = rupture_from_dict_and_origin(jdict, origin)
                    _, ffile = os.path.split(fault_file)
                    fbase, _ = os.path.splitext(ffile)
                    jsonfile = os.path.join(event_dir, fbase+'.geojson')
                    rupt.writeGeoJson(jsonfile)
                    os.remove(fault_file)
                except Exception as e:
                    msg = '''WARNING: UNABLE TO PARSE FAULT TEXT FILE. ERROR: 

"%s".

The following text file has been left in place for you to edit manually:

%s
'''
                    errmsg = str(e)
                    print(msg % (errmsg,fault_file))
                

            # if the user wanted to preserve the model parameters found
            # in info.json, set those here
            if args.preserve_params:
                _write_model_conf(shakemap, module_conf, migrate_conf,
                                  event_dir, skip_bounds=args.skip_bounds)

    print('Wrote %i files to %s' % (len(os.listdir(event_dir)), event_dir))


def _write_model_conf(shakemap, module_conf, migrate_conf, event_dir,
                      skip_bounds=False):
    info_json, _ = shakemap.getContentBytes('info.json')
    info_json = info_json.decode('utf-8')
    jsondict = json.loads(info_json)
    eventid = jsondict['input']['event_information']['event_id']
    model = ConfigObj(indent_type='  ')

    model['modeling'] = {
        'bias': {}
    }
    misc_dict = jsondict['processing']['miscellaneous']
    bias_max_mag = misc_dict['bias_max_mag']
    max_range = misc_dict['bias_max_range']
    if bias_max_mag > 0 and max_range > 0:
        model['modeling']['bias']['do_bias'] = True
        model['modeling']['bias']['max_range'] = max_range
        model['modeling']['bias']['max_mag'] = bias_max_mag
    else:
        model['modeling']['bias']['do_bias'] = False

    # get the outlier information
    model['data'] = {
        'outlier': {}
    }
    max_deviation = misc_dict['outlier_deviation_level']
    outlier_max_mag = misc_dict['outlier_max_mag']
    if outlier_max_mag > 0 and max_deviation > 0:
        model['data']['outlier']['do_outlier'] = True
        model['data']['outlier']['max_deviation'] = max_deviation
        model['data']['outlier']['max_mag'] = outlier_max_mag
    else:
        model['data']['outlier']['do_outlier'] = False

    # set the gmice in model.conf
    allowed_gmice = module_conf['gmice_modules'].keys()
    gmm_dict = jsondict['processing']['ground_motion_modules']
    gmice = gmm_dict['mi2pgm']['module']
    # WGRW11 in SM3.5 is WGRW12 in SM4.0
    if gmice == 'WGRW11':
        gmice = 'WGRW12'
    if gmice not in allowed_gmice:
        # If not implemented, then it will fall back on global conf GMICE
        warnings.warn('GMICE %s (event %s) not yet supported in ShakeMap 4.'
                      % (gmice, eventid))
    else:
        model['modeling']['gmice'] = gmice

    # set the gmpe in model.conf
    old_gmpe = gmm_dict['gmpe']['module']
    new_gmpe, reference = migrate_gmpe(old_gmpe, config=migrate_conf)
    model = set_gmpe(new_gmpe, model, eventid)

    # work on map extent/resolution data
    if not skip_bounds:
        model['interp'] = {
            'prediction_location': {}
        }
        map_dict = jsondict['output']['map_information']
        yres_km = map_dict['grid_spacing']['latitude']
        yres_sec = int(round(yres_km * KM2SEC))
        model['interp']['prediction_location']['xres'] = '%ic' % yres_sec
        model['interp']['prediction_location']['yres'] = '%ic' % yres_sec

        model['extent'] = {'bounds': {}}
        xmin = map_dict['min']['longitude']
        xmax = map_dict['max']['longitude']
        ymin = map_dict['min']['latitude']
        ymax = map_dict['max']['latitude']
        model['extent']['bounds']['extent'] = [xmin, ymin, xmax, ymax]

    # done with model.conf, merge with existing file and save
    model_file = os.path.join(event_dir, 'model.conf')
    if os.path.isfile(model_file):
        existing_model = ConfigObj(model_file)
        model.merge(existing_model)
    model.filename = model_file
    model.write()


if __name__ == '__main__':
    parser = get_parser()
    pargs = parser.parse_args()
    main(pargs)
